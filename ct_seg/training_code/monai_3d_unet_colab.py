!pip install -q gputil

import os
import sys
import torch
import pytorch_lightning as pl
from monai.data import CacheDataset, DataLoader
from monai.transforms import (
    Compose, LoadImaged, EnsureChannelFirstd, Orientationd, Spacingd, 
    ScaleIntensityd, CropForegroundd, RandCropByPosNegLabeld, 
    RandAffined, ToTensord, RandGaussianNoised, RandGaussianSmoothd, 
    RandAdjustContrastd, Lambdad, Resized, RandFlipd, RandRotate90d,
    RandSpatialCropD, SpatialPadD, AsDiscreted, ScaleIntensityRanged,
    SpatialPadd, RandSpatialCropd
)
import numpy as np
import time
import psutil
import monai
from monai.networks.nets import UNet, UNETR
from monai.losses import DiceLoss, DiceCELoss
from monai.metrics import DiceMetric
from monai.inferers import sliding_window_inference
from tqdm import tqdm
from torch.optim import AdamW
from torch.cuda.amp import GradScaler, autocast
import nibabel as nib
import random
import torch.nn as nn
from GPUtil import showUtilization
import glob

# æ‰“å°CUDAçŠ¶æ€
print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
print(f"CUDAå¯ç”¨: {torch.cuda.is_available()}")

if torch.cuda.is_available():
    print(f"GPUå‹å·: {torch.cuda.get_device_name(0)}")
    print(f"GPUæ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB")
    
    # éªŒè¯GPUåŠŸèƒ½
    x = torch.rand(1000, 1000).cuda()
    y = torch.rand(1000, 1000).cuda()
    z = torch.matmul(x, y)
    print(f"GPUè®¡ç®—æµ‹è¯•æˆåŠŸ: ç»“æœshape={z.shape}")
else:
    print("CUDAä¸å¯ç”¨")
    
# æ£€æŸ¥nvidia-smiè¾“å‡º
try:
    result = subprocess.run(["nvidia-smi"], capture_output=True, text=True)
    print("\nnvidia-smiè¾“å‡º:")
    print(result.stdout)
except Exception as e:
    print(f"æ— æ³•è¿è¡Œnvidia-smi: {e}")

# å®‰è£…å¿…è¦çš„ä¾èµ–
import subprocess
print("å®‰è£…å¿…è¦çš„ä¾èµ–...")
subprocess.run(["pip", "install", "-q", "SimpleITK"], check=True)
subprocess.run(["pip", "install", "-q", "itk"], check=True)

# éªŒè¯ä¾èµ–å®‰è£…
try:
    import SimpleITK as sitk
    print(f"SimpleITKç‰ˆæœ¬: {sitk.Version_MajorVersion()}.{sitk.Version_MinorVersion()}")
    
    import itk
    print(f"ITKç‰ˆæœ¬: {itk.Version.GetITKVersion()}")
except ImportError as e:
    print(f"é”™è¯¯: {e}ï¼Œè¯·ç¡®ä¿å®‰è£…æ­£ç¡®")

# ä½¿ç”¨ITKReader
from monai.data.image_reader import ITKReader

# CUDAè¾…åŠ©å‡½æ•°
def force_cuda_init():
    """å¼ºåˆ¶åˆå§‹åŒ–CUDA"""
    if not torch.cuda.is_available():
        print("å°è¯•å¼ºåˆ¶åˆå§‹åŒ–CUDA...")
        # å°è¯•è§£é™¤ç¯å¢ƒå˜é‡é™åˆ¶
        if 'CUDA_VISIBLE_DEVICES' in os.environ:
            print(f"å‘ç°CUDA_VISIBLE_DEVICES={os.environ['CUDA_VISIBLE_DEVICES']}ï¼Œå°è¯•æ¸…é™¤")
            os.environ['CUDA_VISIBLE_DEVICES'] = ''
            
        # å°è¯•å¼ºåˆ¶åŠ è½½CUDAåº“
        try:
            torch.zeros(1).cuda()
            return torch.cuda.is_available()
        except:
            print("å¼ºåˆ¶åˆå§‹åŒ–CUDAå¤±è´¥")
            return False
    return True

def is_cuda_available():
    """æ£€æŸ¥CUDAæ˜¯å¦å¯ç”¨ï¼ŒåŒ…æ‹¬å¤šç§æ£€æµ‹æ–¹æ³•"""
    # åŸºç¡€æ£€æŸ¥
    basic_available = torch.cuda.is_available()
    if basic_available:
        return True
        
    # å¦‚æœåŸºç¡€æ£€æŸ¥å¤±è´¥ï¼Œå°è¯•å¼ºåˆ¶åˆå§‹åŒ–
    return force_cuda_init()

def reset_cuda():
    """å°è¯•é‡ç½®CUDAçŠ¶æ€"""
    try:
        # å®Œå…¨é‡Šæ”¾å¹¶é‡ç½®CUDA
        if is_cuda_available():
            print("é‡ç½®CUDAè®¾å¤‡...")
            
            # å…ˆæ¸…é™¤ç¼“å­˜
            torch.cuda.empty_cache()
            
            # åŒæ­¥æ‰€æœ‰CUDAæµ
            torch.cuda.synchronize()
            
            # è®°å½•å½“å‰å†…å­˜çŠ¶æ€
            allocated = torch.cuda.memory_allocated()
            reserved = torch.cuda.memory_reserved()
            print(f"é‡ç½®åGPUå†…å­˜: å·²åˆ†é…={allocated/1e9:.2f}GB, ä¿ç•™={reserved/1e9:.2f}GB")
            
            return True
    except Exception as e:
        print(f"é‡ç½®CUDAå¤±è´¥: {e}")
        return False

# å°†ç§å­åˆå§‹åŒ–åˆ†ç¦»åˆ°ç‹¬ç«‹å‡½æ•°
def safe_init_random(seed):
    """å®‰å…¨åœ°åˆå§‹åŒ–éšæœºç§å­"""
    try:
        # å…ˆè®¾ç½®CPUéšæœºç§å­
        import random
        random.seed(seed)
        np.random.seed(seed)
        torch.manual_seed(seed)
        
        # ç„¶åå°è¯•è®¾ç½®CUDAç§å­
        if is_cuda_available():
            try:
                # å°è¯•å•ç‹¬è®¾ç½®è®¾å¤‡0çš„ç§å­ï¼Œé¿å…è®¾å¤‡é—´é€šä¿¡
                torch.cuda.manual_seed(seed)
                print("æˆåŠŸè®¾ç½®CUDAéšæœºç§å­")
                return True
            except Exception as e:
                print(f"è®¾ç½®CUDAç§å­å¤±è´¥: {e}")
                return False
        return True
    except Exception as e:
        print(f"åˆå§‹åŒ–éšæœºç§å­å¤±è´¥: {e}")
        return False

# æ‰“å°ç³»ç»Ÿä¿¡æ¯
def print_system_info():
    print("\n======== ç³»ç»Ÿä¿¡æ¯ ========")
    print(f"Pythonç‰ˆæœ¬: {sys.version}")
    print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
    print(f"MONAIç‰ˆæœ¬: {monai.__version__}")
    print(f"å¯ç”¨CPUæ ¸å¿ƒ: {psutil.cpu_count(logical=True)}")
    print(f"å¯ç”¨å†…å­˜: {psutil.virtual_memory().total / (1024**3):.2f} GB")
    
    # å®‰å…¨åœ°è·å–CUDAä¿¡æ¯
    try:
        # æ˜¾ç¤ºNVIDIA-SMIè¾“å‡ºä»¥éªŒè¯ç³»ç»ŸGPUçŠ¶æ€
        try:
            print("\n--- NVIDIA-SMI è¾“å‡º ---")
            result = subprocess.run(["nvidia-smi"], capture_output=True, text=True, check=False)
            print(result.stdout)
        except Exception as e:
            print(f"è¿è¡Œnvidia-smiå¤±è´¥: {e}")
            
        if is_cuda_available():
            print(f"CUDAç‰ˆæœ¬: {torch.version.cuda}")
            for i in range(torch.cuda.device_count()):
                print(f"GPU: {torch.cuda.get_device_name(i)}")
                print(f"GPUæ˜¾å­˜: {torch.cuda.get_device_properties(i).total_memory / (1024**3):.2f} GB")
    except Exception as e:
        print(f"æ— æ³•è·å–GPUä¿¡æ¯: {e}")

def calculate_num_classes(label_dir):
    """è‡ªåŠ¨ä»æ ‡ç­¾æ–‡ä»¶ä¸­è®¡ç®—ç±»åˆ«æ•°"""
    max_label = 0
    label_files = [f for f in os.listdir(label_dir) if f.endswith('.nii.gz')]
    
    for label_file in tqdm(label_files, desc="åˆ†ææ ‡ç­¾æ–‡ä»¶"):
        file_path = os.path.join(label_dir, label_file)
        try:
            label_data = nib.load(file_path).get_fdata()
            current_max = int(np.max(label_data))
            if current_max > max_label:
                max_label = current_max
        except Exception as e:
            print(f"å¤„ç†æ–‡ä»¶ {label_file} æ—¶å‡ºé”™: {e}")
            raise
    
    # å¤„ç†ä¸åŒæƒ…å†µ
    if max_label == 0:
        num_classes = 1  # åªæœ‰èƒŒæ™¯
    else:
        num_classes = max_label + 1  # å‡è®¾æ ‡ç­¾ä»0å¼€å§‹è¿ç»­
    
    print(f"\nè‡ªåŠ¨æ£€æµ‹ç»“æœ:")
    print(f"æœ€å¤§æ ‡ç­¾å€¼: {max_label}")
    print(f"è®¡ç®—ç±»åˆ«æ•°: {num_classes} (åŒ…å«èƒŒæ™¯)")
    return num_classes

# æ£€æŸ¥æ•°æ®é›†
def check_dataset(data_dir):
    # ç¡®ä¿è·¯å¾„æ­£ç¡®
    image_dir = os.path.join(data_dir, 'images')
    label_dir = os.path.join(data_dir, 'labels')
    
    # æ·»åŠ è·¯å¾„å­˜åœ¨æ€§æ£€æŸ¥
    if not os.path.exists(image_dir):
        raise FileNotFoundError(f"å›¾åƒç›®å½•ä¸å­˜åœ¨: {image_dir}")
    if not os.path.exists(label_dir):
        raise FileNotFoundError(f"æ ‡ç­¾ç›®å½•ä¸å­˜åœ¨: {label_dir}")
    
    # è·å–å®Œæ•´æ–‡ä»¶è·¯å¾„
    image_files = sorted([os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith('.nii.gz')])
    label_files = sorted([os.path.join(label_dir, f) for f in os.listdir(label_dir) if f.endswith('.nii.gz')])
    
    # æ·»åŠ æ–‡ä»¶å¯è®¿é—®æ€§æ£€æŸ¥
    for f in image_files[:3]:  # æ£€æŸ¥å‰3ä¸ªæ–‡ä»¶
        if not os.access(f, os.R_OK):
            raise PermissionError(f"æ— æ³•è¯»å–å›¾åƒæ–‡ä»¶: {f}")
    for f in label_files[:3]:
        if not os.access(f, os.R_OK):
            raise PermissionError(f"æ— æ³•è¯»å–æ ‡ç­¾æ–‡ä»¶: {f}")
    
    # æ‰“å°éªŒè¯é€šè¿‡çš„ç¤ºä¾‹è·¯å¾„
    print("\néªŒè¯é€šè¿‡çš„ç¤ºä¾‹è·¯å¾„:")
    print(f"å›¾åƒ: {image_files[0]}")
    print(f"æ ‡ç­¾: {label_files[0]}")
    
    # è‡ªåŠ¨è®¡ç®—ç±»åˆ«æ•°
    a100_optimized_config['num_classes'] = calculate_num_classes(label_dir)
    
    # éªŒè¯æ ‡ç­¾è¿ç»­æ€§
    all_labels = set()
    sample_files = random.sample(label_files, min(5, len(label_files)))
    for f in sample_files:
        label_data = nib.load(f).get_fdata()
        all_labels.update(np.unique(label_data).astype(int))
    
    expected_labels = set(range(a100_optimized_config['num_classes']))
    missing = expected_labels - all_labels
    if missing:
        print(f"è­¦å‘Š: ç¼ºå°‘ä»¥ä¸‹æ ‡ç­¾å€¼: {missing}ï¼Œå¯èƒ½å½±å“è®­ç»ƒæ•ˆæœ")

# å…¶ä»–ä»£ç ä¿æŒä¸å˜ (CT3DDataModule, CT3DSegmentationModelç­‰)
class CT3DDataModule(pl.LightningDataModule):
    def __init__(self, config):
        super().__init__()
        self.data_dir = config['data_dir']
        self.batch_size = config['batch_size']
        self.patch_size = config.get('patch_size', (128, 128, 128))
        self.num_workers = config.get('num_workers', 4)
        self.val_ratio = config.get('val_ratio', 0.2)
        self.cache_rate = config.get('cache_rate', 0.0)
        self.spatial_size = config.get('spatial_size', None)

    def prepare_data(self):
        pass

    def setup(self, stage=None):
        # æŸ¥æ‰¾æ‰€æœ‰å›¾åƒå’Œæ ‡ç­¾æ–‡ä»¶
        images_dir = os.path.join(self.data_dir, 'images')
        labels_dir = os.path.join(self.data_dir, 'labels')
        
        print(f"è¯»å–å›¾åƒç›®å½•: {images_dir}")
        print(f"è¯»å–æ ‡ç­¾ç›®å½•: {labels_dir}")
        
        # æŸ¥æ‰¾æ‰€æœ‰.nii.gzæ–‡ä»¶
        image_files = sorted([os.path.join(images_dir, f) for f in os.listdir(images_dir) if f.endswith('.nii.gz')])
        label_files = sorted([os.path.join(labels_dir, f) for f in os.listdir(labels_dir) if f.endswith('.nii.gz')])
        
        # éªŒè¯åŒ¹é…çš„æ–‡ä»¶å¯¹
        image_names = [os.path.basename(f) for f in image_files]
        label_names = [os.path.basename(f) for f in label_files]
        
        # æŸ¥æ‰¾åŒ¹é…çš„æ–‡ä»¶å¯¹
        matching_pairs = []
        for i, img_name in enumerate(image_names):
            if img_name in label_names:
                img_path = image_files[i]
                label_path = label_files[label_names.index(img_name)]
                matching_pairs.append((img_path, label_path))
        
        print(f"æ‰¾åˆ°{len(matching_pairs)}å¯¹åŒ¹é…çš„å›¾åƒå’Œæ ‡ç­¾æ–‡ä»¶")
        
        if len(matching_pairs) > 0:
            print("ç¤ºä¾‹åŒ¹é…å¯¹:")
            for i in range(min(3, len(matching_pairs))):
                img_path, label_path = matching_pairs[i]
                print(f"  å›¾åƒ: {os.path.basename(img_path)}")
                print(f"  æ ‡ç­¾: {os.path.basename(label_path)}")
        
        # å‡†å¤‡æ•°æ®å­—å…¸
        data_dicts = []
        for img_path, label_path in matching_pairs:
            data_dicts.append({
                "image": img_path,
                "label": label_path
            })
        
        print(f"æ‰¾åˆ°{len(data_dicts)}å¯¹.nii.gzæ ¼å¼çš„åŒ¹é…å›¾åƒ-æ ‡ç­¾æ–‡ä»¶")
        
        # éšæœºåˆ†å‰²æ•°æ®é›†
        n_val = int(len(data_dicts) * self.val_ratio)
        n_train = len(data_dicts) - n_val
        
        import random
        random.seed(42)  # ç¡®ä¿å¯é‡å¤æ€§
        random.shuffle(data_dicts)
        
        self.train_files = data_dicts[:n_train]
        self.val_files = data_dicts[n_train:]
        
        print(f"éšæœºåˆ†å‰²æ•°æ®é›†: è®­ç»ƒé›† {len(self.train_files)}ä¸ªæ ·æœ¬, éªŒè¯é›† {len(self.val_files)}ä¸ªæ ·æœ¬")
        
        # å®šä¹‰æ•°æ®è½¬æ¢
        self.train_transforms = self._get_transforms(train=True)
        self.val_transforms = self._get_transforms(train=False)
        
        # åˆ›å»ºæ•°æ®é›†
        self.train_ds = CacheDataset(
            data=self.train_files, 
            transform=self.train_transforms,
            cache_rate=self.cache_rate,
            num_workers=self.num_workers,
            progress=True
        )
        
        self.val_ds = CacheDataset(
            data=self.val_files, 
            transform=self.val_transforms,
            cache_rate=self.cache_rate,
            num_workers=self.num_workers,
            progress=True
        )

    def _get_transforms(self, train=True):
        # ç¡®ä¿è¯»å–å™¨å¯ä»¥å¤„ç†.nii.gzæ–‡ä»¶
        reader = ITKReader()
        
        # é»˜è®¤è½¬æ¢ç®¡é“
        if self.spatial_size is None:
            # åŸå§‹ç©ºé—´å¤§å°çš„è½¬æ¢
            if train:
                return Compose([
                    LoadImaged(keys=["image", "label"], reader=reader, image_only=True),
                    EnsureChannelFirstd(keys=["image", "label"]),
                    Orientationd(keys=["image", "label"], axcodes="RAS"),
                    Spacingd(keys=["image", "label"], pixdim=(1.0, 1.0, 1.0), mode=("bilinear", "nearest")),
                    ScaleIntensityd(keys=["image"]),
                    CropForegroundd(keys=["image", "label"], source_key="image"),
                    
                    # å…ˆå¡«å……åˆ°è‡³å°‘ç›®æ ‡å°ºå¯¸
                    SpatialPadd(
                        keys=['image', 'label'],
                        spatial_size=self.patch_size,
                        mode='constant'
                    ),
                    
                    # å†éšæœºè£å‰ªåˆ°ç²¾ç¡®å°ºå¯¸
                    RandSpatialCropd(
                        keys=['image', 'label'],
                        roi_size=self.patch_size,
                        random_center=True,
                        random_size=False
                    ),
                    
                    # æ•°æ®å¢å¼º
                    RandFlipd(keys=["image", "label"], prob=0.5, spatial_axis=0),
                    RandFlipd(keys=["image", "label"], prob=0.5, spatial_axis=1),
                    RandFlipd(keys=["image", "label"], prob=0.5, spatial_axis=2),
                    RandRotate90d(keys=["image", "label"], prob=0.5, max_k=3, spatial_axes=(0, 1)),
                    RandRotate90d(keys=["image", "label"], prob=0.5, max_k=3, spatial_axes=(1, 2)),
                    RandRotate90d(keys=["image", "label"], prob=0.5, max_k=3, spatial_axes=(0, 2)),
                    RandGaussianNoised(keys=["image"], prob=0.15, mean=0.0, std=0.1),
                    RandGaussianSmoothd(
                        keys=["image"],
                        prob=0.15,
                        sigma_x=(0.5, 1.5),
                        sigma_y=(0.5, 1.5),
                        sigma_z=(0.5, 1.5),
                    ),
                    RandAdjustContrastd(keys=["image"], prob=0.15, gamma=(0.7, 1.3)),
                    ToTensord(keys=["image", "label"]),
                    Lambdad(
                        keys=['label'],
                        func=lambda x: torch.where(x > 24, 0, x)  # å¤„ç†å¼‚å¸¸æ ‡ç­¾å€¼
                    ),
                    Lambdad(
                        keys=['label'],
                        func=lambda x: torch.nn.functional.one_hot(
                            x.squeeze(1).long(),  # å…³é”®ï¼šå»é™¤é€šé“ç»´åº¦ [B,1,H,W,D] â†’ [B,H,W,D]
                            num_classes=self.num_classes
                        ).permute(0, 4, 1, 2, 3)  # [B,H,W,D,C] â†’ [B,C,H,W,D]
                    ),
                    EnsureChannelFirstd(keys=['label'], channel_dim=1),  # ç¡®è®¤é€šé“ä½ç½®
                    Resized(
                        keys=['image', 'label'],
                        spatial_size=(64, 64, 64),  # ä¸‹é‡‡æ ·åˆ°64^3
                        mode=('trilinear', 'nearest')
                    )
                ])
            else:
                return Compose([
                    LoadImaged(keys=["image", "label"], reader=reader, image_only=True),
                    EnsureChannelFirstd(keys=["image", "label"]),
                    Orientationd(keys=["image", "label"], axcodes="RAS"),
                    Spacingd(keys=["image", "label"], pixdim=(1.0, 1.0, 1.0), mode=("bilinear", "nearest")),
                    ScaleIntensityd(keys=["image"]),
                    CropForegroundd(keys=["image", "label"], source_key="image"),
                    ToTensord(keys=["image", "label"]),
                ])
        else:
            # ä½¿ç”¨å›ºå®šç©ºé—´å¤§å°çš„è½¬æ¢
            if train:
                return Compose([
                    LoadImaged(keys=["image", "label"], reader=reader, image_only=True),
                    EnsureChannelFirstd(keys=["image", "label"]),
                    Orientationd(keys=["image", "label"], axcodes="RAS"),
                    Spacingd(keys=["image", "label"], pixdim=(1.0, 1.0, 1.0), mode=("bilinear", "nearest")),
                    ScaleIntensityd(keys=["image"]),
                    CropForegroundd(keys=["image", "label"], source_key="image"),
                    Resized(keys=["image", "label"], spatial_size=self.spatial_size, mode=("trilinear", "nearest")),
                    
                    # å…ˆå¡«å……åˆ°è‡³å°‘ç›®æ ‡å°ºå¯¸
                    SpatialPadd(
                        keys=['image', 'label'],
                        spatial_size=self.patch_size,
                        mode='constant'
                    ),
                    
                    # å†éšæœºè£å‰ªåˆ°ç²¾ç¡®å°ºå¯¸
                    RandSpatialCropd(
                        keys=['image', 'label'],
                        roi_size=self.patch_size,
                        random_center=True,
                        random_size=False
                    ),
                    
                    # æ•°æ®å¢å¼º
                    RandFlipd(keys=["image", "label"], prob=0.5, spatial_axis=0),
                    RandFlipd(keys=["image", "label"], prob=0.5, spatial_axis=1),
                    RandFlipd(keys=["image", "label"], prob=0.5, spatial_axis=2),
                    RandRotate90d(keys=["image", "label"], prob=0.5, max_k=3, spatial_axes=(0, 1)),
                    RandRotate90d(keys=["image", "label"], prob=0.5, max_k=3, spatial_axes=(1, 2)),
                    RandRotate90d(keys=["image", "label"], prob=0.5, max_k=3, spatial_axes=(0, 2)),
                    RandGaussianNoised(keys=["image"], prob=0.15, mean=0.0, std=0.1),
                    RandGaussianSmoothd(
                        keys=["image"],
                        prob=0.15,
                        sigma_x=(0.5, 1.5),
                        sigma_y=(0.5, 1.5),
                        sigma_z=(0.5, 1.5),
                    ),
                    RandAdjustContrastd(keys=["image"], prob=0.15, gamma=(0.7, 1.3)),
                    ToTensord(keys=["image", "label"]),
                    Lambdad(
                        keys=['label'],
                        func=lambda x: torch.where(x > 24, 0, x)  # å¤„ç†å¼‚å¸¸æ ‡ç­¾å€¼
                    ),
                    Lambdad(
                        keys=['label'],
                        func=lambda x: torch.nn.functional.one_hot(
                            x.squeeze(1).long(),  # å…³é”®ï¼šå»é™¤é€šé“ç»´åº¦ [B,1,H,W,D] â†’ [B,H,W,D]
                            num_classes=self.num_classes
                        ).permute(0, 4, 1, 2, 3)  # [B,H,W,D,C] â†’ [B,C,H,W,D]
                    ),
                    EnsureChannelFirstd(keys=['label'], channel_dim=1),  # ç¡®è®¤é€šé“ä½ç½®
                    Resized(
                        keys=['image', 'label'],
                        spatial_size=(64, 64, 64),  # ä¸‹é‡‡æ ·åˆ°64^3
                        mode=('trilinear', 'nearest')
                    )
                ])
            else:
                return Compose([
                    LoadImaged(keys=["image", "label"], reader=reader, image_only=True),
                    EnsureChannelFirstd(keys=["image", "label"]),
                    Orientationd(keys=["image", "label"], axcodes="RAS"),
                    Spacingd(keys=["image", "label"], pixdim=(1.0, 1.0, 1.0), mode=("bilinear", "nearest")),
                    ScaleIntensityd(keys=["image"]),
                    CropForegroundd(keys=["image", "label"], source_key="image"),
                    Resized(keys=["image", "label"], spatial_size=self.spatial_size, mode=("trilinear", "nearest")),
                    ToTensord(keys=["image", "label"]),
                ])

    def train_dataloader(self):
        return DataLoader(
            self.train_ds, 
            batch_size=self.batch_size, 
            shuffle=True,
            num_workers=self.num_workers,
            pin_memory=True
        )

    def val_dataloader(self):
        return DataLoader(
            self.val_ds, 
            batch_size=self.batch_size, 
            shuffle=False,
            num_workers=self.num_workers,
            pin_memory=True
        )

class BTCVModel(nn.Module):
    def __init__(self, config):
        super().__init__()
        # è‡ªåŠ¨æ£€æµ‹è®¾å¤‡
        self.device = config['device']
        print(f"æ¨¡å‹å°†è¿è¡Œåœ¨: {self.device}")
        
        # ç‰ˆæœ¬å…¼å®¹çš„GradScaler
        if hasattr(torch.cuda.amp, 'GradScaler'):
            self.scaler = torch.cuda.amp.GradScaler()  # æ–°ç‰ˆæœ¬
        else:
            self.scaler = torch.amp.GradScaler(device_type='cuda')  # æ—§ç‰ˆæœ¬å…¼å®¹
            
        # ç®€åŒ–UNetç»“æ„
        self.model = UNet(
            spatial_dims=3,
            in_channels=1,
            out_channels=8,
            channels=(16, 32, 64),  # å‡å°‘å±‚æ•°
            strides=(2, 2),
            num_res_units=1
        ).to(self.device)
        self.loss_function = DiceCELoss(
            to_onehot_y=False,  # æ ‡ç­¾å·²ç»æ˜¯one-hot
            softmax=True,       # æ¨¡å‹è¾“å‡ºéœ€è¦softmax
            squared_pred=True
        )
        self.optimizer = AdamW(self.parameters(), lr=config['learning_rate'])

    def forward(self, x):
        return self.model(x)

def get_data_loaders(config):
    """åˆ›å»ºè®­ç»ƒå’ŒéªŒè¯æ•°æ®åŠ è½½å™¨ - å†…å­˜ä¼˜åŒ–ç‰ˆæœ¬"""
    image_dir = os.path.join(config['data_dir'], 'images')
    label_dir = os.path.join(config['data_dir'], 'labels')
    
    image_files = sorted([os.path.join(image_dir, f) for f in os.listdir(image_dir) 
                        if f.endswith('.nii.gz')])
    label_files = sorted([os.path.join(label_dir, f) for f in os.listdir(label_dir)
                        if f.endswith('.nii.gz')])
    
    data_dicts = [{'image': img, 'label': lbl} 
                for img, lbl in zip(image_files, label_files)]
    
    # åˆ›å»ºæ•°æ®è½¬æ¢
    train_transforms = Compose([
        LoadImaged(keys=['image', 'label'], reader=ITKReader(io_args={'mode': 'r'})),
        EnsureChannelFirstd(keys=['image', 'label']),
        # æå‰é™é‡‡æ ·ä»¥å‡å°‘å†…å­˜ä½¿ç”¨
        Spacingd(
            keys=['image', 'label'],
            pixdim=(2.0, 2.0, 2.0),  # å¢åŠ ä½“ç´ å¤§å°æ¥å‡å°‘æ•°æ®é‡
            mode=('bilinear', 'nearest')
        ),
        # ä½¿ç”¨æ ‡å‡†åŒ–æ›¿ä»£one-hotç¼–ç æ¥å‡å°‘å†…å­˜
        Lambdad(
            keys=['label'],
            func=lambda x: x.squeeze(1).long()  # ä»…å‹ç¼©é€šé“ï¼Œä¸è¿›è¡Œone-hot
        ),
        # å‡å°crop sizeä»¥å‡å°‘å†…å­˜ä½¿ç”¨
        RandSpatialCropd(
            keys=['image', 'label'], 
            roi_size=(64, 64, 64),  # å‡å°ROIå¤§å°
            random_size=False
        ),
        ScaleIntensityRanged(keys=['image'], a_min=-1000, a_max=1000, b_min=0.0, b_max=1.0),
        ToTensord(keys=['image', 'label'])
    ])
    
    val_transforms = Compose([
        LoadImaged(keys=['image', 'label']),
        EnsureChannelFirstd(keys=['image', 'label']),
        Spacingd(
            keys=['image', 'label'],
            pixdim=(2.0, 2.0, 2.0),
            mode=('bilinear', 'nearest')
        ),
        Lambdad(
            keys=['label'],
            func=lambda x: x.squeeze(1).long()
        ),
        ScaleIntensityRanged(keys=['image'], a_min=-1000, a_max=1000, b_min=0.0, b_max=1.0),
        ToTensord(keys=['image', 'label'])
    ])
    
    # ä¿®æ”¹1: ä½¿ç”¨PersistentDatasetè€Œä¸æ˜¯CacheDataset
    cache_dir = os.path.join(config['log_dir'], 'dataset_cache')
    os.makedirs(cache_dir, exist_ok=True)
    
    from monai.data import PersistentDataset
    
    train_ds = PersistentDataset(
        data=data_dicts[:int(len(data_dicts) * 0.8)],
        transform=train_transforms,
        cache_dir=cache_dir  # ç¼“å­˜åˆ°ç£ç›˜è€Œä¸æ˜¯å†…å­˜
    )
    
    val_ds = PersistentDataset(
        data=data_dicts[int(len(data_dicts) * 0.8):],
        transform=val_transforms,
        cache_dir=cache_dir
    )
    
    # ä¿®æ”¹2: å‡å°batch_sizeå’Œworkersæ•°é‡
    reduced_batch_size = max(1, config['batch_size'] // 2)  # å‡åŠbatch_size
    reduced_workers = max(0, config['num_workers'] // 2)  # å‡åŠworkeræ•°
    
    train_loader = DataLoader(
        train_ds,
        batch_size=reduced_batch_size,  # å‡å°batch_size 
        shuffle=True,
        num_workers=reduced_workers,    # å‡å°‘workeræ•°é‡
        pin_memory=False                # å…³é—­pin_memoryé™ä½å†…å­˜å‹åŠ›
    )
    
    val_loader = DataLoader(
        val_ds,
        batch_size=reduced_batch_size,
        shuffle=False,
        num_workers=reduced_workers,
        pin_memory=False
    )
    
    # ä¿®æ”¹3: æ·»åŠ å†…å­˜æ¸…ç†å‡½æ•°
    def cleanup_memory():
        """æ‰‹åŠ¨æ¸…ç†å†…å­˜"""
        import gc
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            
    cleanup_memory()  # ç«‹å³æ‰§è¡Œæ¸…ç†
    
    return train_loader, val_loader, cleanup_memory  # è¿”å›æ¸…ç†å‡½æ•°ä¾›åç»­ä½¿ç”¨

def train_model(config):
    """å†…å­˜ä¼˜åŒ–ç‰ˆæœ¬çš„è®­ç»ƒå‡½æ•°"""
    # è·å–æ•°æ®åŠ è½½å™¨å’Œæ¸…ç†å‡½æ•°
    train_loader, val_loader, cleanup_memory = get_data_loaders(config)
    
    # ä¿®æ”¹æ¨¡å‹ä»¥æ”¯æŒéone-hotç¼–ç æ ‡ç­¾
    model = UNet(
        spatial_dims=3,
        in_channels=1,
        out_channels=config['num_classes'], 
        channels=(16, 32, 64, 128),     # å‡å°‘é€šé“æ•°
        strides=(2, 2, 2),              # å‡å°‘å±‚æ•°
        dropout=0.2                      # æ·»åŠ dropout
    ).to(config['device'])
    
    # ä¿®æ”¹æŸå¤±å‡½æ•°ä»¥æ”¯æŒéone-hotç¼–ç æ ‡ç­¾ 
    loss_function = DiceCELoss(
        to_onehot_y=True,               # ç°åœ¨éœ€è¦è½¬æ¢ä¸ºone-hot
        softmax=True,
        squared_pred=True,
        include_background=True
    )
    
    optimizer = torch.optim.AdamW(
        model.parameters(),
        lr=config['learning_rate'],
        weight_decay=1e-5
    )
    
    # ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒå‡å°‘å†…å­˜ä½¿ç”¨
    from torch.cuda.amp import GradScaler, autocast
    scaler = GradScaler()
    
    # è®­ç»ƒå¾ªç¯
    for epoch in range(config['num_epochs']):
        model.train()
        epoch_loss = 0
        
        # æ¯ä¸ªepochç»“æŸåæ¸…ç†å†…å­˜
        cleanup_memory()
        
        # åœ¨è®­ç»ƒå¾ªç¯ä¸­ä½¿ç”¨æ··åˆç²¾åº¦
        for batch_idx, batch_data in enumerate(train_loader):
            inputs, labels = batch_data['image'].to(config['device']), batch_data['label'].to(config['device'])
            
            optimizer.zero_grad()
            
            # ä½¿ç”¨æ··åˆç²¾åº¦
            with autocast():
                outputs = model(inputs)
                loss = loss_function(outputs, labels)
            
            # ä½¿ç”¨æ¢¯åº¦ç¼©æ”¾å™¨
            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()
            
            epoch_loss += loss.item()
            
            # æ¯4ä¸ªæ‰¹æ¬¡æ¸…ç†ä¸€æ¬¡å†…å­˜
            if batch_idx % 4 == 0:
                cleanup_memory()
                
            # å®šæœŸæ‰“å°å†…å­˜ä½¿ç”¨æƒ…å†µ
            if batch_idx % 10 == 0:
                print(f"GPUå†…å­˜: {torch.cuda.memory_allocated()/1e9:.1f}GB / {torch.cuda.memory_reserved()/1e9:.1f}GB")
                
        print(f"Epoch {epoch+1}/{config['num_epochs']}, å¹³å‡æŸå¤±: {epoch_loss/len(train_loader):.4f}")
        
        # éªŒè¯å¾ªç¯
        model.eval()
        with torch.no_grad():
            # ...éªŒè¯ä»£ç ...
            pass
            
        # å¼ºåˆ¶æ¸…ç†å†…å­˜
        cleanup_memory()
        
    return model

def monitor_resources():
    """ç»Ÿä¸€çš„èµ„æºç›‘æ§å‡½æ•°"""
    try:
        from GPUtil import showUtilization
        showUtilization()
    except ImportError:
        print("GPUç›‘æ§ä¸å¯ç”¨ï¼Œä½¿ç”¨åŸºç¡€æ–¹æ¡ˆï¼š")
        if torch.cuda.is_available():
            print(f"å·²åˆ†é…å†…å­˜: {torch.cuda.memory_allocated()/1e9:.2f}GB")
            print(f"ä¿ç•™å†…å­˜: {torch.cuda.memory_reserved()/1e9:.2f}GB")
    
    # æ·»åŠ ç³»ç»Ÿå†…å­˜ç›‘æ§
    import psutil
    print(f"ç³»ç»Ÿå†…å­˜ä½¿ç”¨: {psutil.virtual_memory().percent}%")

# A100ä¼˜åŒ–é…ç½® - ä½¿ç”¨NIfTIæ–‡ä»¶
a100_optimized_config = {
    'data_dir': '/content/drive/MyDrive/ct_segmentation/3DU-net',  # æŒ‡å‘åŒ…å«imageså’Œlabelså­ç›®å½•çš„ç›®å½•
    'log_dir': '/content/drive/MyDrive/ct_segmentation/3DU-net/logs',
    'checkpoint_dir': '/content/drive/MyDrive/ct_segmentation/3DU-net/checkpoints',
    'experiment_name': '3d_unet_a100_nifti',
    'batch_size': 2,
    'patch_size': (128, 128, 128),
    'num_workers': 4,
    'learning_rate': 3e-4,
    'original_labels': [0,1,2,11,12,21,22,23],  # å®é™…å­˜åœ¨çš„æ ‡ç­¾
    'include_background': True,
    'max_epochs': 200,
    'gpus': 1,
    'precision': 16,
    'accumulate_grad_batches': 1,
    'seed': 42,
    'val_ratio': 0.2,
    'cache_rate': 0.2,
    'resume_checkpoint': None,
    'spatial_size': (128, 128, 128),  # è®¾ç½®ç»Ÿä¸€çš„ç©ºé—´å¤§å°
    'weight_decay': 1e-5,  # æ–°å¢æƒé‡è¡°å‡å‚æ•°
    'ignored_labels': [3,4,5,6,7,8,9,10,15,16,17,18,19,20,24],
    'valid_labels': [0,1,2,3,4,5,6,7],         # é‡æ–°æ˜ å°„åçš„æ ‡ç­¾ç´¢å¼•
    'device': torch.device("cuda" if torch.cuda.is_available() else "cpu"),  # æ–°å¢è®¾å¤‡é…ç½®
    'label_remapping': {
        0:0, 1:1, 2:2, 11:3, 12:4, 21:5, 22:6, 23:7
    },
    'persistent_workers': True,
    'loss_function': DiceCELoss(
        to_onehot_y=False,  # æ ‡ç­¾å·²ç»æ˜¯one-hot
        softmax=True,       # æ¨¡å‹è¾“å‡ºéœ€è¦softmax
        squared_pred=True,
        include_background=True
    ),
    'dice_metric': DiceMetric(include_background=True),
    'num_classes': 25,  # æ ¹æ®è‡ªåŠ¨æ£€æµ‹ç»“æœè®¾ç½®
    'in_channels': 1,
    'train_ratio': 0.8,  # 80%è®­ç»ƒï¼Œ20%éªŒè¯
    'num_epochs': 200  # æ–°å¢num_epochså‚æ•°
}

# å¼ºåˆ¶è®­ç»ƒå‰è¿›è¡ŒCUDAæ£€æµ‹å’Œåˆå§‹åŒ–
if __name__ == "__main__":
    # é¦–å…ˆå°è¯•å¼ºåˆ¶åˆå§‹åŒ–CUDA
    cuda_initialized = force_cuda_init()
    
    # å°è¯•å®‰å…¨åœ°æ£€æŸ¥CUDAå¯ç”¨æ€§
    gpu_available = is_cuda_available()
    
    # å¦‚æœCUDAä¸å¯ç”¨ï¼Œå°è¯•ä¿®å¤
    if not gpu_available:
        print("\nâŒ CUDAæ£€æµ‹å¤±è´¥ï¼Œå°è¯•è§£å†³æ–¹æ¡ˆ...")
        print("1. æ£€æŸ¥CUDAå®‰è£…çŠ¶æ€...")
        
        # æ£€æŸ¥NVCCç‰ˆæœ¬
        try:
            result = subprocess.run(["nvcc", "--version"], capture_output=True, text=True, check=False)
            print(result.stdout)
        except:
            print("æœªæ‰¾åˆ°nvcc")
            
        # æ£€æŸ¥GPUé©±åŠ¨
        try:
            result = subprocess.run(["nvidia-smi"], capture_output=True, text=True, check=False)
            print(result.stdout)
        except:
            print("æœªæ‰¾åˆ°nvidia-smi")
            
        # æç¤ºç”¨æˆ·è¿›è¡Œæ‰‹åŠ¨æ“ä½œ
        print("\nğŸ”§ å»ºè®®è§£å†³æ–¹æ¡ˆ:")
        print("- åœ¨Colabèœå•ä¸­é€‰æ‹©: Runtime > Factory reset runtime")
        print("- è¿è¡Œæ—¶é‡æ–°å¯åŠ¨åï¼Œåœ¨è®¾ç½®ä¸­ç¡®è®¤GPUå·²å¯ç”¨: Runtime > Change runtime type")
        print("- é‡æ–°è¿è¡Œæ­¤ä»£ç ")
        print("\nå°è¯•ç»§ç»­ä½¿ç”¨CPUè®­ç»ƒï¼Œä½†æ•ˆç‡ä¼šéå¸¸ä½...")
    
    if gpu_available:
        print("âœ… CUDAå¯ç”¨ï¼Œç»§ç»­åˆå§‹åŒ–...")
        try:
            # å°è¯•åŸºæœ¬çš„CUDAè®¾å¤‡æ£€æŸ¥
            device_count = torch.cuda.device_count()
            print(f"æ£€æµ‹åˆ° {device_count} ä¸ªCUDAè®¾å¤‡")
            
            for i in range(device_count):
                print(f"è®¾å¤‡ {i}: {torch.cuda.get_device_name(i)}")
                
            # å°è¯•é‡ç½®æ‰€æœ‰CUDAè®¾å¤‡
            reset_cuda()
        except Exception as e:
            print(f"CUDAåˆå§‹åŒ–æ£€æŸ¥å¤±è´¥: {e}")
            gpu_available = False
    
    # æ‰“å°ç³»ç»Ÿä¿¡æ¯
    print_system_info()
    
    # æ£€æŸ¥æ•°æ®é›†
    check_dataset('/content/drive/MyDrive/ct_segmentation/3DU-net')
    
    print("\n======== å¼€å§‹3D U-Netè®­ç»ƒ ========")
    start_time = time.time()
    
    try:
        model = train_model(a100_optimized_config)
        total_time = time.time() - start_time
        print(f"\næ€»è®­ç»ƒæ—¶é—´: {total_time//3600}å°æ—¶ {(total_time%3600)//60}åˆ†é’Ÿ {total_time%60:.1f}ç§’")
    except KeyboardInterrupt:
        print("\nè®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        import traceback
        log_path = os.path.join(a100_optimized_config['log_dir'], 'error_log.txt')
        print(f"\nè®­ç»ƒå¤±è´¥: {e}")
        print(f"é”™è¯¯æ—¥å¿—å·²ä¿å­˜åˆ°: {log_path}")
        
        # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
        os.makedirs(a100_optimized_config['log_dir'], exist_ok=True)
        
        # å†™å…¥é”™è¯¯ä¿¡æ¯
        with open(log_path, 'w') as f:
            traceback.print_exc(file=f)
        traceback.print_exc()
        print("é‡åˆ°é”™è¯¯ï¼Œä½†å…è®¸ç»§ç»­æ‰§è¡Œ")

# ä¿®æ”¹auto_detect_classeså‡½æ•°å‚æ•°
def auto_detect_classes(label_files, ignored_labels):
    all_labels = set()
    for f in tqdm(label_files, desc="åˆ†ææ ‡ç­¾æ–‡ä»¶"):
        img = nib.load(f).get_fdata()
        all_labels.update(np.unique(img).astype(int))
    return len(all_labels - set(ignored_labels))

# æ•°æ®è·¯å¾„å¤„ç†
def prepare_datasets(config):
    # è·å–æ‰€æœ‰é…å¯¹æ–‡ä»¶
    images = sorted(glob.glob(os.path.join(config['data_dir'], 'images', '*.nii.gz')))
    labels = sorted(glob.glob(os.path.join(config['data_dir'], 'labels', '*.nii.gz')))
    
    # éªŒè¯æ–‡ä»¶é…å¯¹
    assert len(images) == len(labels), "å›¾åƒå’Œæ ‡ç­¾æ•°é‡ä¸åŒ¹é…"
    print(f"æ‰¾åˆ°{len(images)}ä¸ªæœ‰æ•ˆæ•°æ®å¯¹")
    
    # åˆ›å»ºæ•°æ®å­—å…¸åˆ—è¡¨
    data_dicts = [{'image': img, 'label': lbl} for img, lbl in zip(images, labels)]
    
    # éšæœºåˆ†å‰²è®­ç»ƒé›†å’ŒéªŒè¯é›†
    random.seed(42)
    random.shuffle(data_dicts)
    split = int(len(data_dicts) * config['train_ratio'])
    train_files = data_dicts[:split]
    val_files = data_dicts[split:]
    
    print(f"\næ•°æ®é›†åˆ†å‰²ç»“æœ:")
    print(f"è®­ç»ƒé›†: {len(train_files)}ä¸ªæ ·æœ¬")
    print(f"éªŒè¯é›†: {len(val_files)}ä¸ªæ ·æœ¬")
    print(f"ç¤ºä¾‹è®­ç»ƒæ ·æœ¬: {train_files[0]['image']}")
    
    return train_files, val_files

# è°ƒç”¨æ•°æ®å‡†å¤‡
train_files, val_files = prepare_datasets(a100_optimized_config)

# æ›´æ–°è‡ªåŠ¨æ£€æµ‹å‡½æ•°è°ƒç”¨
num_classes = auto_detect_classes(
    [d['label'] for d in train_files],  # ä»…ä½¿ç”¨è®­ç»ƒé›†ç»Ÿè®¡
    ignored_labels=a100_optimized_config.get('ignored_labels', [])
)

# æ›´æ–°é…ç½®
a100_optimized_config['num_classes'] = num_classes 

# æ·»åŠ å†…å­˜ç›‘æ§
monitor_resources()  # åœ¨æ¯ä¸ªepochå¼€å§‹å‰è°ƒç”¨ 

# æç®€åŒ–é¢„å¤„ç†æµç¨‹ï¼ˆä¿®å¤æ‹¬å·åŒ¹é…ï¼‰
train_transforms = Compose([
    LoadImaged(keys=['image', 'label'], reader=ITKReader()),
    EnsureChannelFirstd(keys=['image', 'label']),
    Lambdad(keys=['label'], func=lambda x: torch.from_numpy(np.vectorize(config['label_remapping'].get)(x.squeeze(0).numpy(), 0)).long()),
    AsDiscreted(keys=['label'], to_onehot=num_classes, num_classes=num_classes),
    RandSpatialCropd(keys=['image', 'label'], roi_size=(96, 96, 96), random_size=False),
    ToTensord(keys=['image', 'label'])
])

# ä¿®æ”¹2ï¼šæ›´æ–°æ¨¡å‹è¾“å‡ºé€šé“
model = UNet(
    spatial_dims=3,
    in_channels=1,
    out_channels=num_classes,  # ä½¿ç”¨è‡ªåŠ¨æ£€æµ‹çš„ç±»åˆ«æ•°
    channels=(16, 32, 64, 128, 256),
    strides=(2, 2, 2, 2)
).to(config['device'])

# ä¿®æ”¹3ï¼šè°ƒæ•´æŸå¤±å‡½æ•°é…ç½® 
a100_optimized_config['loss_function'] = DiceCELoss(
    to_onehot_y=False,  # æ ‡ç­¾å·²ç¼–ç 
    softmax=True,
    squared_pred=True,
    include_background=True
)

# éªŒè¯æ­¥éª¤
sample = train_transforms(train_files[0])
print("\né¢„å¤„ç†åç»´åº¦éªŒè¯:")
print(f"å›¾åƒç»´åº¦: {sample['image'].shape}")
print(f"æ ‡ç­¾ç»´åº¦: {sample['label'].shape}") 

# é€æ­¥æµ‹è¯•æµç¨‹ï¼ˆé¿å…å¤æ‚åµŒå¥—ï¼‰
# 1. åŠ è½½æµ‹è¯•æ ·æœ¬
test_sample = train_files[0]
print(f"æµ‹è¯•æ ·æœ¬: {test_sample['image']}")

# 2. æµ‹è¯•åŸºç¡€è½¬æ¢  
basic_transforms = Compose([
    LoadImaged(keys=['image', 'label']),
    EnsureChannelFirstd(keys=['image', 'label']),
    ToTensord(keys=['image', 'label'])
])

# 3. åº”ç”¨è½¬æ¢æµ‹è¯•
processed = basic_transforms(test_sample)
print(f"åŸºç¡€è½¬æ¢å: å›¾åƒ={processed['image'].shape}, æ ‡ç­¾={processed['label'].shape}")

# 4. åˆ›å»ºæ¨¡å‹æµ‹è¯•
test_model = UNet(
    spatial_dims=3,
    in_channels=1,
    out_channels=num_classes,
    channels=(16, 32, 64),
    strides=(2, 2)
).to(config['device'])

print(f"æ¨¡å‹åˆ›å»ºæˆåŠŸ! å‚æ•°æ•°é‡: {sum(p.numel() for p in test_model.parameters())}") 